{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('train_preprocessed.npy', allow_pickle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(550784,)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'given': array([[9.5041323e-01, 4.8211467e-01, 9.2348807e-02, 9.2435157e-01,\n         8.7563485e-01, 0.0000000e+00, 3.4531930e-03, 7.4778247e-01,\n         0.0000000e+00, 3.0276409e-04, 1.0000000e+00, 9.8877323e-01,\n         4.7489539e-01, 5.1176184e-01, 4.1326246e-01, 6.0996467e-01,\n         7.4185000e-04, 3.7985889e-03, 8.6159718e-01, 8.6855656e-01,\n         5.7556349e-01, 5.9469765e-01, 2.6509967e-01, 1.6594577e-01,\n         1.7335278e-01, 0.0000000e+00, 1.1757903e-01, 2.7688432e-01,\n         1.6001400e-02, 5.9639150e-01, 4.0206063e-01, 4.1554055e-01,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n         7.5000000e-01, 0.0000000e+00, 9.1134632e-01, 8.4772384e-01,\n         6.7977655e-01, 4.1184431e-01, 4.3498287e-01, 8.4418401e-02,\n         7.0660597e-01, 0.0000000e+00, 0.0000000e+00, 3.0887550e-01,\n         5.1020408e-01, 7.7428329e-01, 6.9515103e-01, 0.0000000e+00,\n         6.1130112e-01, 4.8246446e-01, 5.1273537e-01, 5.1076430e-01,\n         9.9067557e-01, 2.8169015e-01, 9.9991953e-01, 0.0000000e+00,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n        [9.5041323e-01, 4.8196557e-01, 9.2348807e-02, 9.2435157e-01,\n         8.7563485e-01, 0.0000000e+00, 3.7985889e-03, 7.4762917e-01,\n         0.0000000e+00, 3.0276409e-04, 1.0000000e+00, 9.8807710e-01,\n         4.6575150e-01, 5.1176184e-01, 4.0583536e-01, 5.9378278e-01,\n         1.2982254e-03, 2.7626448e-03, 8.7719196e-01, 8.7215710e-01,\n         5.7476532e-01, 5.9469765e-01, 2.6509967e-01, 1.6593418e-01,\n         1.7335278e-01, 0.0000000e+00, 1.1757903e-01, 2.7608019e-01,\n         1.8362261e-02, 6.0239249e-01, 4.0206063e-01, 5.9121621e-01,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n         7.5000000e-01, 0.0000000e+00, 3.4700629e-01, 5.3417653e-01,\n         6.7073590e-01, 7.9424119e-01, 7.9102397e-01, 8.0078125e-02,\n         7.1440959e-01, 0.0000000e+00, 0.0000000e+00, 3.0887550e-01,\n         5.1020408e-01, 7.7741081e-01, 7.0254427e-01, 0.0000000e+00,\n         6.2351519e-01, 4.7488153e-01, 5.1052862e-01, 5.1309150e-01,\n         9.9067557e-01, 2.8169015e-01, 9.9991953e-01, 0.0000000e+00,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n        [9.5041323e-01, 4.8216438e-01, 9.2348807e-02, 9.2435157e-01,\n         8.7563485e-01, 0.0000000e+00, 2.7626448e-03, 7.4787009e-01,\n         0.0000000e+00, 3.7820695e-04, 1.0000000e+00, 9.8807710e-01,\n         4.6105024e-01, 5.1176184e-01, 4.1803697e-01, 5.8185941e-01,\n         1.1127507e-03, 4.8344983e-03, 8.8303983e-01, 8.8656205e-01,\n         5.7146883e-01, 5.9469765e-01, 2.6591009e-01, 1.6593161e-01,\n         1.7335278e-01, 0.0000000e+00, 1.1757903e-01, 2.7608019e-01,\n         1.8012503e-02, 5.9639150e-01, 4.0206063e-01, 3.5810810e-01,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n         7.5000000e-01, 0.0000000e+00, 8.4121734e-01, 6.4901143e-01,\n         5.3875387e-01, 2.5667351e-01, 4.6267137e-01, 7.6244213e-02,\n         7.2140032e-01, 0.0000000e+00, 0.0000000e+00, 3.0887550e-01,\n         5.1020408e-01, 7.8010350e-01, 7.1189374e-01, 0.0000000e+00,\n         6.2190425e-01, 5.0331753e-01, 5.1981580e-01, 5.1512814e-01,\n         9.9067557e-01, 2.8169015e-01, 9.9991953e-01, 0.0000000e+00,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n        [9.5041323e-01, 4.8295960e-01, 9.2348807e-02, 9.2435157e-01,\n         8.7563485e-01, 0.0000000e+00, 4.8344983e-03, 7.4903089e-01,\n         0.0000000e+00, 2.2732123e-04, 1.0000000e+00, 9.8815423e-01,\n         4.4135207e-01, 5.1176184e-01, 4.1538465e-01, 6.0144788e-01,\n         9.2727604e-04, 4.1438458e-03, 9.1617936e-01, 8.9196426e-01,\n         5.6949693e-01, 5.9469765e-01, 2.6428846e-01, 1.6587240e-01,\n         1.7335278e-01, 0.0000000e+00, 1.4687741e-01, 2.7608019e-01,\n         1.9673850e-02, 5.9639150e-01, 4.0464488e-01, 4.4256756e-01,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n         7.5000000e-01, 0.0000000e+00, 5.3126031e-01, 7.9169899e-01,\n         7.9344696e-01, 7.6848048e-01, 6.4636892e-01, 7.2627313e-02,\n         7.2801173e-01, 0.0000000e+00, 0.0000000e+00, 3.0887550e-01,\n         5.1020408e-01, 7.8270978e-01, 7.1863407e-01, 0.0000000e+00,\n         6.2472308e-01, 5.1753557e-01, 5.1714939e-01, 5.2211034e-01,\n         9.9067557e-01, 2.8169015e-01, 9.9991953e-01, 0.0000000e+00,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n        [9.5041323e-01, 4.8251230e-01, 9.2348807e-02, 9.2435157e-01,\n         8.7563485e-01, 0.0000000e+00, 4.1438458e-03, 7.4837381e-01,\n         0.0000000e+00, 3.0276409e-04, 1.0000000e+00, 9.8815423e-01,\n         4.5879367e-01, 5.1176184e-01, 4.1007945e-01, 5.9718949e-01,\n         1.2055123e-03, 3.4531930e-03, 8.7719196e-01, 9.2257470e-01,\n         5.6283009e-01, 5.9469765e-01, 2.6509967e-01, 1.6590071e-01,\n         1.7335278e-01, 0.0000000e+00, 1.1757903e-01, 2.7565134e-01,\n         2.0023609e-02, 6.0239249e-01, 3.9949328e-01, 4.1554055e-01,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n         7.5000000e-01, 0.0000000e+00, 5.6665564e-01, 4.1696727e-01,\n         4.8399171e-01, 4.1963786e-01, 6.5284920e-01, 6.8938076e-02,\n         7.3446053e-01, 0.0000000e+00, 0.0000000e+00, 3.0887550e-01,\n         5.1020408e-01, 7.8601146e-01, 7.2450513e-01, 0.0000000e+00,\n         6.3438696e-01, 5.0047392e-01, 5.2551723e-01, 5.2269167e-01,\n         9.9067557e-01, 2.8169015e-01, 9.9991953e-01, 0.0000000e+00,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n        [9.5041323e-01, 4.8385423e-01, 9.2348807e-02, 9.2435157e-01,\n         8.7563485e-01, 0.0000000e+00, 3.4531930e-03, 7.5036687e-01,\n         0.0000000e+00, 3.0276409e-04, 1.0000000e+00, 9.8823130e-01,\n         4.6039209e-01, 5.1176184e-01, 4.2440322e-01, 5.8867300e-01,\n         1.2982254e-03, 4.4892412e-03, 8.7134504e-01, 8.8656205e-01,\n         5.7035208e-01, 5.9469765e-01, 2.6388323e-01, 1.6581962e-01,\n         1.7335278e-01, 0.0000000e+00, 1.1757903e-01, 2.7688432e-01,\n         1.8362261e-02, 5.9639150e-01, 4.0206063e-01, 4.1554055e-01,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n         7.2916669e-01, 0.0000000e+00, 7.8167385e-01, 8.9018768e-01,\n         7.5999081e-01, 5.6827515e-01, 5.0160670e-01, 6.5682873e-02,\n         7.4031323e-01, 0.0000000e+00, 0.0000000e+00, 3.0887550e-01,\n         5.0649351e-01, 7.8844476e-01, 7.3102790e-01, 0.0000000e+00,\n         6.3257498e-01, 5.0710899e-01, 5.3241360e-01, 5.2657127e-01,\n         9.9067557e-01, 2.8169015e-01, 9.9991953e-01, 0.0000000e+00,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n        [9.5041323e-01, 4.8464945e-01, 9.2348807e-02, 9.2435157e-01,\n         8.7563485e-01, 0.0000000e+00, 4.4892412e-03, 7.5154954e-01,\n         0.0000000e+00, 3.0276409e-04, 1.0000000e+00, 9.8799998e-01,\n         4.7067997e-01, 4.7764438e-01, 4.0159157e-01, 6.1166805e-01,\n         1.7618390e-03, 4.8344983e-03, 8.4990239e-01, 8.8116044e-01,\n         5.7252520e-01, 5.9469765e-01, 2.6428846e-01, 1.6577971e-01,\n         1.7335278e-01, 0.0000000e+00, 1.1757903e-01, 2.7608019e-01,\n         1.8668300e-02, 5.9035099e-01, 3.9949328e-01, 5.9121621e-01,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n         7.2916669e-01, 0.0000000e+00, 3.2947403e-01, 4.1381672e-01,\n         5.7635611e-01, 6.9404519e-01, 7.9846829e-01, 6.2500000e-02,\n         7.4573243e-01, 0.0000000e+00, 0.0000000e+00, 3.0887550e-01,\n         5.0649351e-01, 7.9096335e-01, 7.3602962e-01, 0.0000000e+00,\n         6.3928610e-01, 4.8246446e-01, 5.3360903e-01, 5.2754074e-01,\n         9.9067557e-01, 2.8169015e-01, 9.9991953e-01, 0.0000000e+00,\n         0.0000000e+00, 0.0000000e+00, 0.0000000e+00]], dtype=float32),\n 'answer': array([9.5041323e-01, 4.8678660e-01, 9.2348807e-02, 9.2435157e-01,\n        8.7563485e-01, 0.0000000e+00, 6.5610944e-03, 7.5463766e-01,\n        0.0000000e+00, 3.0276409e-04, 1.0000000e+00, 9.8892850e-01,\n        4.7827244e-01, 4.4764417e-01, 4.1220137e-01, 6.0144788e-01,\n        1.1127507e-03, 3.4531930e-03, 8.3430767e-01, 8.7035710e-01,\n        5.7561713e-01, 5.9469765e-01, 2.6347801e-01, 1.6614273e-01,\n        1.7335278e-01, 0.0000000e+00, 1.1757903e-01, 2.7565134e-01,\n        1.8012503e-02, 5.9639150e-01, 4.0206063e-01, 7.0608109e-01,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n        7.2916669e-01, 0.0000000e+00, 3.9960304e-01, 6.4175153e-01,\n        7.3879993e-01, 8.1356168e-01, 7.5439161e-01, 5.6495950e-02,\n        7.5619143e-01, 0.0000000e+00, 0.0000000e+00, 3.0792826e-01,\n        5.0649351e-01, 7.9539520e-01, 7.4777055e-01, 0.0000000e+00,\n        6.4686930e-01, 4.7772512e-01, 5.3765494e-01, 5.3200221e-01,\n        9.9067557e-01, 2.8169015e-01, 9.9991953e-01, 0.0000000e+00,\n        0.0000000e+00, 0.0000000e+00, 0.0000000e+00], dtype=float32)}"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convol2anomal(keras.Model) :\n",
    "    def __init__(self, original_dim) :\n",
    "        super(self, Convol2anomal).__init__()\n",
    "        self.original_dim = original_dim\n",
    "        self.conv2d_1 = layers.Conv2D(filters=32  , kernel_size = (3,3) , padding='same')\n",
    "        self.maxpool_1 = layers.MaxPool2D()\n",
    "        self.conv2d_2 = layers.Conv2D(filters=16, kernel_size=(3,3) , padding='same')\n",
    "        self.maxpool_2 = layers.MaxPooling2D()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.Dense_1 = layers.Dense(63)\n",
    "    \n",
    "    def call(self, inputs) : \n",
    "        x = self.conv2d_1(inputs)\n",
    "        x = self.maxpool_1(x)\n",
    "        x = self.conv2d_2(x)\n",
    "        x = self.maxpool_2(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.Dense_1(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "given =  np.array([i['given'] for i in train ])\n",
    "answer = np.array([i['answer'] for i in train ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "mse_loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "loss_metric = tf.keras.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "super() argument 1 must be type, not Convol2anomal",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-a875e7ad1abd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mConvol2anomal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m56\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmse_loss_fn\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-7c9abcf7fcea>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, original_dim)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConvol2anomal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConvol2anomal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super() argument 1 must be type, not Convol2anomal"
     ]
    }
   ],
   "source": [
    "Convol2anomal(original_dim = (56,10)).compile( optimizer = optimizer, loss=mse_loss_fn , metrics=loss_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(given)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'BatchDataset' object is not subscriptable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-8383b84b4616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'BatchDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "train_dataset[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Start of epoch 0\n"
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-37a46da49b56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;31m# if step == 0 and epoch == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0;31m#   vae._set_inputs(x_batch_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mreconstructed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvol2anomal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0;31m# Compute reconstruction loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "  print('Start of epoch %d' % (epoch,))\n",
    "\n",
    "  # Iterate over the batches of the dataset.\n",
    "  for step, x_batch_train in enumerate(train_dataset):\n",
    "    with tf.GradientTape() as tape:\n",
    "      # !!! uncomment the following two lines to use workaround and skip !!!\n",
    "      # if step == 0 and epoch == 0:\n",
    "      #   vae._set_inputs(x_batch_train)\n",
    "      reconstructed = Convol2anomal(x_batch_train)\n",
    "      # Compute reconstruction loss\n",
    "      loss = mse_loss_fn(x_batch_train, reconstructed)\n",
    "      loss += sum(vae.losses)  # Add KLD regularization loss\n",
    "\n",
    "    grads = tape.gradient(loss, Convol2anomal.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, Convol2anomal.trainable_weights))\n",
    "\n",
    "    loss_metric(loss)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "      print('step %s: mean loss = %s' % (step, loss_metric.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}