{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('train_preprocessed.npy', allow_pickle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "  def call(self, inputs):\n",
    "    z_mean, z_log_var = inputs\n",
    "    batch = tf.shape(z_mean)[1]\n",
    "    dim = tf.shape(z_mean)[2]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class anomal_dacon_encoder(tf.keras.Model) :\n",
    "    def __init__(self, input_length, z_dimension):\n",
    "        super(anomal_dacon_encoder, self).__init__()\n",
    "        self.lstm_proj = tf.keras.layers.LSTM(input_length)\n",
    "        self.dense_mean = tf.keras.layers.Dense(z_dimension)\n",
    "        self.dense_log_var = tf.keras.layers.Dense(z_dimension)\n",
    "        self.sampling = Sampling()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.keras.layers.Input(shape=(63,7))\n",
    "        x = self.lstm_proj(inputs)\n",
    "        z_mean = self.dense_mean(x)\n",
    "        z_log_var = self.dense_log_var(x)\n",
    "        z = self.sampling((z_mean, z_log_var))\n",
    "        \n",
    "        return z_mean, z_log_var, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class anomal_dacon_generator(tf.keras.Model) :\n",
    "    def __init__(self, input_length, timesteps):\n",
    "        super(anomal_dacon_generator, self).__init__()\n",
    "        self.lstm_proj = tf.keras.layers.LSTM(input_length , return_sequences= True)\n",
    "        self.repeatvector = tf.keras.layers.RepeatVector(timesteps)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.repeatvector(inputs)\n",
    "        x= self.lstm_proj(x)\n",
    "        \n",
    "        return x \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class anomal_dacon_discriminator(tf.keras.Model) :\n",
    "    def __init__(self, input_length):\n",
    "        super(anomal_dacon_discriminator, self).__init__()\n",
    "        self.lstm_proj = tf.keras.layers.LSTM(input_length , return_sequences= True)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense_toone = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        proj_x =self.lstm_proj(inputs)\n",
    "        x = self.flatten(proj_x)\n",
    "        result = self.dense_toone(x)\n",
    "        return proj_x, result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "given =  np.array([i['given'] for i in train ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(550784, 7, 63)"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "given.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = given.shape[1]\n",
    "input_length = given.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = anomal_dacon_generator(input_length= input_length ,timesteps = timesteps   )\n",
    "discriminator = anomal_dacon_discriminator(input_length = input_length)\n",
    "encoder = anomal_dacon_encoder(input_length = input_length , z_dimension = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(x_hat, x_gen , x_real):\n",
    "    dis_xhat = discriminator(x_hat)\n",
    "    dis_xgen = discriminator(x_gen)\n",
    "    dis_xreal = discriminator(x_real)\n",
    "\n",
    "    return -tf.math.log(1-dis_xgen) -tf.math.log(1-dis_xhat) -tf.math.log(dis_xreal)\n",
    "\n",
    "def generator_loss(x_hat , x_gen,  reconstruction_error):\n",
    "    dis_xhat = discriminator(x_hat)\n",
    "    dis_xgen = discriminator(x_gen)\n",
    "    temp = -tf.math.log(dis_xgen) - tf.math.log(dis_xhat) \n",
    "    return temp + reconstruction_error\n",
    "\n",
    "def encoder_loss(x_real, x_encoded):\n",
    "    KLdivergence_loss = tf.keras.losses.KLDivergence()\n",
    "    encode_loss = KLdivergence_loss(x_real, x_encoded)\n",
    "    reconstruction_error = tf.keras.losses.BinaryCrossentropy(from_logits=True)(x_real, x_encoded)\n",
    "    encoder_loss += reconstruction_error\n",
    "    return encode_loss , reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = tf.optimizers.Adam(1e-4)\n",
    "generator_optimizer = tf.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x_batch_train, encoder_optimizer, generator_optimizer,discriminator_optimizer  ):\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape ,  tf.GradientTape() as enc_tape :\n",
    "            log_var, mean, z = encoder(x_batch_train)\n",
    "            fake_window = generator(z)\n",
    "            fake_result = discriminator(fake_window)\n",
    "            real_result = discriminator(x_batch_train)\n",
    "            e_loss , r_loss = encoder_loss(x_batch_train. fake_window) \n",
    "            g_loss = generator_loss( z, fake_window, r_loss)\n",
    "            d_loss = discriminator_loss(real_result, fake_result)\n",
    "            \n",
    "            gradients_of_encoder = enc_tape.gradient(e_loss , encoder.trainable_variables )\n",
    "            gradients_of_generator = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "            gradients_of_discriminator = disc_tape.gradient(d_loss , discriminator.trainable_variables)\n",
    "            \n",
    "            encoder_optimizer.apply_gradients(zip(gradients_of_encoder, encoder.trainable_variables))\n",
    "            generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "            discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "            return e_loss , g_loss , d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_mean = tf.metrics.Mean()\n",
    "d_mean = tf.metrics.Mean()\n",
    "g_mean = tf.metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0%|          | 0/100 [00:00<?, ?it/s]ERROR:root:Internal Python error in the inspect module.\nBelow is the traceback from this internal error.\n\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-38-6ab043591339>\", line 4, in <module>\n    e_loss ,d_loss, g_loss = train_step(timewindow, encoder_optimizer, generator_optimizer,discriminator_optimizer)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 580, in __call__\n    result = self._call(*args, **kwds)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 627, in _call\n    self._initialize(args, kwds, add_initializers_to=initializers)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 506, in _initialize\n    *args, **kwds))\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2446, in _get_concrete_function_internal_garbage_collected\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\n    graph_function = self._create_graph_function(args, kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\n    capture_by_value=self._capture_by_value),\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\n    func_outputs = python_func(*func_args, **func_kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 441, in wrapped_fn\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 964, in wrapper\n    user_requested=True,\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 585, in converted_call\n    result = converted_f(*effective_args, **kwargs)\n  File \"/var/folders/04/rzd4lkdx48q5g1zpxyt0sfm80000gn/T/tmpieysp5i6.py\", line 11, in tf__train_step\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 492, in converted_call\n    return _call_unconverted(f, args, kwargs, options)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 348, in _call_unconverted\n    return f(*args)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 927, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 262, in wrapper\n    return converted_call(f, args, kwargs, options=options)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 585, in converted_call\n    result = converted_f(*effective_args, **kwargs)\n  File \"/var/folders/04/rzd4lkdx48q5g1zpxyt0sfm80000gn/T/tmprt1in93a.py\", line 11, in tf__call\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 492, in converted_call\n    return _call_unconverted(f, args, kwargs, options)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 348, in _call_unconverted\n    return f(*args)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 654, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 927, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\", line 1187, in call\n    runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\", line 1566, in lstm_with_backend_selection\n    **params)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2420, in __call__\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1665, in _filtered_call\n    self.captured_inputs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1751, in _call_flat\n    forward_function, args_with_tangents = forward_backward.forward()\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1477, in forward\n    self._inference_args, self._input_tangents)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1233, in forward\n    self._forward_and_backward_functions(inference_args, input_tangents))\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1433, in _forward_and_backward_functions\n    outputs, inference_args, input_tangents)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 937, in _build_functions_for_outputs\n    graph_placeholder(gradient_dtype, gradient_shape))\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/graph_only_ops.py\", line 40, in graph_placeholder\n    attrs=attrs, name=name)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 595, in _create_op_internal\n    compute_device)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3327, in _create_op_internal\n    op_def=op_def)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1828, in __init__\n    output_type = pywrap_tf_session.TF_OperationOutputType(tf_output)\nKeyboardInterrupt\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n    stb = value._render_traceback_()\nAttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n    return f(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n  File \"/opt/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n  File \"/opt/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n    filename = getsourcefile(frame) or getfile(frame)\n  File \"/opt/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n  File \"/opt/anaconda3/lib/python3.7/inspect.py\", line 725, in getmodule\n    file = getabsfile(object, _filename)\n  File \"/opt/anaconda3/lib/python3.7/inspect.py\", line 709, in getabsfile\n    return os.path.normcase(os.path.abspath(_filename))\n  File \"/opt/anaconda3/lib/python3.7/posixpath.py\", line 383, in abspath\n    cwd = os.getcwd()\nKeyboardInterrupt\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for epoch in tqdm(range(100)):\n",
    "    for timewindow in dataset:\n",
    "        e_loss ,d_loss, g_loss = train_step(timewindow, encoder_optimizer, generator_optimizer,discriminator_optimizer)\n",
    "        e_mean.update_state(e_loss)\n",
    "        d_mean.update_state(d_loss)\n",
    "        g_mean.update_state(g_loss)\n",
    "\n",
    "    print('epoch: {}, e_loss: {} ,d_loss: {}, g_loss: {}'.format(epoch+1,e_mean.result() ,d_mean.result(), g_mean.result()))\n",
    "    e_mean.reset_states()\n",
    "    d_mean.reset_states()\n",
    "    g_mean.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}